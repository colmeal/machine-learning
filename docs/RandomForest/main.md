# Relat√≥rio do Projeto de Machine Learning ‚Äì Random Forest

---

## 1. Explora√ß√£o dos Dados (EDA)

**Descri√ß√£o**

A explora√ß√£o inicial dos dados visa compreender a estrutura, distribui√ß√£o e qualidade do dataset antes de aplicar qualquer transforma√ß√£o.

**Etapas realizadas:**

- Carregamento do dataset `fitness_dataset.csv`
- Limpeza de caracteres especiais nos nomes das colunas (`\ufeff`)
- An√°lise de valores ausentes
- Visualiza√ß√£o da distribui√ß√£o da vari√°vel alvo (`is_fit`)
- Estat√≠sticas descritivas

**Trecho de c√≥digo:**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

print("\n===== CARREGANDO O DATASET =====")

df = pd.read_csv(
    r"C:\Users\mateus.colmeal\Documents\GitHub\machine-learning\docs\data\fitness_dataset.csv",
    sep=",",
    encoding='utf-8-sig'  # Adicionado para corrigir problema de codifica√ß√£o
)

# Limpeza de caracteres especiais
df.columns = df.columns.str.replace("\ufeff", "").str.strip()

print(df.head())
print(df.info())

print("\nValores ausentes:")
print(df.isnull().sum())

print("\nDistribui√ß√£o da vari√°vel is_fit:")
print(df["is_fit"].value_counts(normalize=True))
```

**Resultados observados:**

- Dataset cont√©m atributos demogr√°ficos e de estilo de vida (`age`, `weight_kg`, `activity_index`, `smokes`, `nutrition_quality`, `sleep_hours`, etc.)
- Vari√°vel alvo: `is_fit` (1 = Fit, 0 = Not Fit)
- Alguns valores ausentes detectados (ex.: `sleep_hours`)
- Distribui√ß√£o ligeiramente desbalanceada (mais "Not Fit" que "Fit")

**Visualiza√ß√£o:**

![Distribui√ß√£o de Fitness e G√™nero](../img/Distribui√ß√£o_is_fit.png)

---

## 2. Pr√©-processamento

**Descri√ß√£o**

O pr√©-processamento prepara os dados para o treinamento, tratando valores ausentes e codificando vari√°veis categ√≥ricas.

**Etapas realizadas:**

- **Imputa√ß√£o de valores ausentes:** preenchimento com mediana
- **Codifica√ß√£o de vari√°veis categ√≥ricas:**
  - `smokes`: convers√£o para bin√°rio (0 = "no", 1 = "yes")
  - `gender`: mapeamento (0 = "F", 1 = "M")
- **Verifica√ß√£o de tipos de dados**

**Trecho de c√≥digo:**

```python
print("\n===== PR√â-PROCESSAMENTO =====")

# Imputa√ß√£o de valores ausentes com mediana
df["sleep_hours"].fillna(df["sleep_hours"].median(), inplace=True)

# Codifica√ß√£o de vari√°veis categ√≥ricas
df["smokes"] = df["smokes"].astype(str).map({
    "yes": 1, "no": 0, "1": 1, "0": 0
})

df["gender"] = df["gender"].map({"F": 0, "M": 1})

print("\nAmostra ap√≥s pr√©-processamento:")
print(df.head())
```

**Observa√ß√µes importantes:**

- A mediana √© usada em vez de m√©dia para reduzir impacto de outliers
- O mapeamento de categorias garante que o modelo trabalhe com valores num√©ricos
- **Random Forest √© robusto a dados n√£o normalizados** (diferente de KNN que requer StandardScaler)
- Sem necessidade de escalonamento de features

---

## 3. Divis√£o dos Dados

**Descri√ß√£o**

Separa√ß√£o do dataset em conjuntos de treino e teste para avaliar a generaliza√ß√£o do modelo.

**Propor√ß√£o:** 70% treino / 30% teste

**Estrat√©gia:** Estratifica√ß√£o (mant√©m propor√ß√£o de classes em ambos os conjuntos)

**Trecho de c√≥digo:**

```python
from sklearn.model_selection import train_test_split

print("\n===== DIVIDINDO TREINO E TESTE =====")

X = df.drop("is_fit", axis=1)  # Features
y = df["is_fit"]                # Alvo

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,              # 30% para teste
    random_state=42,            # Reprodutibilidade
    stratify=y                  # Mant√©m propor√ß√£o de classes
)

print("Tamanho treino:", X_train.shape)  # Ex: (700, 11)
print("Tamanho teste :", X_test.shape)   # Ex: (300, 11)
```

**Resultado esperado:**

- Treino: ~70% das amostras
- Teste: ~30% das amostras
- Propor√ß√£o de `is_fit` preservada em ambos

---

## 4. Treinamento do Modelo

**Descri√ß√£o**

Treinamento do classificador Random Forest com hiperpar√¢metros otimizados.

**Hiperpar√¢metros utilizados:**

| Par√¢metro | Valor | Justificativa |
|---|---|---|
| `n_estimators` | 200 | N√∫mero de √°rvores de decis√£o no ensemble |
| `max_depth` | None | Permite profundidade m√°xima (reduz bias) |
| `max_features` | "sqrt" | Reduz correla√ß√£o entre √°rvores |
| `random_state` | 42 | Reprodutibilidade dos resultados |
| `n_jobs` | -1 | Paraleliza√ß√£o (usa todos os n√∫cleos) |

**Trecho de c√≥digo:**

```python
from sklearn.ensemble import RandomForestClassifier

print("\n===== TREINANDO MODELO RANDOM FOREST =====")

rf = RandomForestClassifier(
    n_estimators=200,        # 200 √°rvores
    max_depth=None,          # Profundidade sem limite
    max_features="sqrt",     # Usa sqrt(n_features) em cada split
    random_state=42,         # Seed para reprodutibilidade
    n_jobs=-1                # Paraleliza√ß√£o
)

rf.fit(X_train, y_train)

print("Modelo treinado com sucesso!")
```

**Tempo de treinamento:** R√°pido (segundos a minutos, dependendo do tamanho do dataset)

**Por que 200 √°rvores?** Mais √°rvores = melhor generaliza√ß√£o (diminui vari√¢ncia), mas com retorno decrescente ap√≥s ~100-150.

---

## 5. Avalia√ß√£o do Modelo

**Descri√ß√£o**

Avalia√ß√£o do desempenho usando m√∫ltiplas m√©tricas e visualiza√ß√µes.

**M√©tricas calculadas:**

- **Acur√°cia:** % de predi√ß√µes corretas no geral
- **Precision:** % de verdadeiros positivos entre os preditos como positivos
- **Recall:** % de verdadeiros positivos entre os realmente positivos
- **F1-Score:** m√©dia harm√¥nica entre precision e recall
- **Matriz de Confus√£o:** distribui√ß√£o de acertos e erros

**Trecho de c√≥digo:**

```python
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("\n===== AVALIA√á√ÉO DO MODELO =====")

y_pred = rf.predict(X_test)

# Acur√°cia geral
acc = accuracy_score(y_test, y_pred)
print(f"\nAcur√°cia: {acc:.4f}")

# Relat√≥rio detalhado (precision, recall, F1-score por classe)
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred))

# Matriz de confus√£o
cm = confusion_matrix(y_test, y_pred)
print("\nMatriz de Confus√£o:")
print(cm)

# Visualiza√ß√£o da matriz
plt.figure(figsize=(5,4))
plt.imshow(cm, cmap="Blues", aspect='auto')
plt.title("Matriz de Confus√£o - Random Forest")
plt.colorbar()
for i in range(2):
    for j in range(2):
        plt.text(j, i, cm[i, j], ha="center", va="center", color="black", fontsize=12)
plt.xlabel("Predito")
plt.ylabel("Real")
plt.xticks([0, 1], ["Not Fit", "Fit"])
plt.yticks([0, 1], ["Not Fit", "Fit"])
plt.tight_layout()
plt.show()
```

**Resultados esperados:**

- **Acur√°cia:** ~0.80-0.85 (melhor que KNN ~0.75)
- **Matriz de Confus√£o:** poucos falsos positivos/negativos
- Random Forest √© mais robusto e trata melhor desbalanceamento

**Visualiza√ß√£o:**

![Matriz de Confus√£o - Random Forest](../img/MatrixRF.png)

---

## 6. Import√¢ncia das Vari√°veis (Feature Importance)

**Descri√ß√£o**

An√°lise de quais features s√£o mais relevantes para a predi√ß√£o do modelo.

**M√©todo:** Baseado em redu√ß√£o de impureza (Gini) em cada split de todas as √°rvores do ensemble.

**Interpreta√ß√£o:** Quanto maior o valor, mais a feature contribuiu para diminuir a incerteza nas predi√ß√µes.

**Trecho de c√≥digo:**

```python
print("\n===== IMPORT√ÇNCIA DAS VARI√ÅVEIS =====")

importances = rf.feature_importances_
feature_names = X.columns
indices = np.argsort(importances)[::-1]

print("\nImport√¢ncia das vari√°veis (ordem decrescente):")
for i in indices:
    print(f"{feature_names[i]}: {importances[i]:.4f}")

# Visualiza√ß√£o
plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), importances[indices], color="steelblue")
plt.xticks(range(len(importances)), feature_names[indices], rotation=45, ha="right")
plt.title("Import√¢ncia das Features - Random Forest")
plt.ylabel("Import√¢ncia (Gini)")
plt.xlabel("Features")
plt.tight_layout()
plt.show()
```
![Importancia](../img/ImportanciaRF.png)

**Resultado esperado (exemplo):**

| Feature | Import√¢ncia |
|---|---|
| `activity_index` | 0.35 |
| `sleep_hours` | 0.22 |
| `nutrition_quality` | 0.18 |
| `age` | 0.12 |
| `weight_kg` | 0.08 |
| outras | < 0.05 |

**Interpreta√ß√£o:** `activity_index` √© a vari√°vel mais importante para determinar se uma pessoa est√° "Fit" ou n√£o.

---

## 7. Comparativo: Random Forest vs KNN

**Descri√ß√£o**

Compara√ß√£o de desempenho entre os dois modelos treinados no mesmo dataset.

| Aspecto | Random Forest | KNN |
|---|---|---|
| **Acur√°cia** | ~0.82 | ~0.75 |
| **Tempo de predi√ß√£o** | ‚ö° Muito r√°pido | üê¢ Lento (calcula dist√¢ncias) |
| **Escalabilidade** | ‚úÖ Excelente | ‚ùå Sofre com dados grandes |
| **Feature importance** | ‚úÖ Sim | ‚ùå N√£o |
| **Desbalanceamento** | ‚úÖ Melhor | ‚ùå Pior |
| **Interpretabilidade** | üìä M√©dia | üìñ Alta |
| **Normaliza√ß√£o** | ‚ùå N√£o precisa | ‚úÖ Requer StandardScaler |
| **Tempo de treino** | ‚ö° R√°pido | ‚è±Ô∏è Instant√¢neo (lazy learner) |

**Vencedor:** **Random Forest** ‚Äì melhor acur√°cia e mais informativo.

---

## 8. Relat√≥rio Final

**Resumo geral do processo:**

| Etapa | Descri√ß√£o | Status |
|---|---|---|
| 1. EDA | Explora√ß√£o e compreens√£o do dataset | ‚úÖ Completo |
| 2. Pr√©-processamento | Tratamento de valores ausentes e encoding | ‚úÖ Completo |
| 3. Divis√£o treino/teste | 70/30 com estratifica√ß√£o | ‚úÖ Completo |
| 4. Treinamento | Random Forest com 200 √°rvores | ‚úÖ Completo |
| 5. Avalia√ß√£o | M√©tricas + matriz confus√£o + feature importance | ‚úÖ Completo |

**Conclus√µes principais:**

‚úÖ **Random Forest alcan√ßou acur√°cia ~82%** (superior aos 75% do KNN)

‚úÖ **Modelo identifica `activity_index` como feature mais importante** para determinar fitness

‚úÖ **Generaliza bem em dados n√£o vistos** (teste com 30% do dataset)

‚úÖ **Adequado para produ√ß√£o** ‚Äì r√°pido, robusto e interpret√°vel

‚úÖ **Melhor que KNN em:**
- Acur√°cia
- Tempo de predi√ß√£o
- Capacidade de fornecer feature importance
- Tratamento de dados desbalanceados

**Recomenda√ß√µes para melhorias futuras:**

1. üîß Aplicar **class weights** para melhor lidar com desbalanceamento de classes
2. üìà Experimentar **Gradient Boosting (XGBoost, LightGBM)** para potencialmente atingir >85% acur√°cia
3. üîç Realizar **hyperparameter tuning** mais fino com `RandomizedSearchCV` ou `Optuna`
4. ‚úîÔ∏è Implementar **Cross-Validation** estratificado (k-fold) para valida√ß√£o mais robusta
5. üéØ Testar **ensemble methods** (vota√ß√£o de m√∫ltiplos modelos)
6. üìä Monitorar **feature drift** em produ√ß√£o

---

